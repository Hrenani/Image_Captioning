# Image_Captioning
# Image Captioning Project

This project uses deep learning techniques to generate captions for images. Given an image, the model produces a descriptive caption based on the content of the image, leveraging a well-known dataset and advanced machine learning libraries.

## Dataset

The project utilizes the [Flickr8k Dataset](https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip), which contains 8,000 images with associated captions, and the corresponding text descriptions are provided in a separate file available [here](https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip).

## Project Structure

The project has been developed in a Jupyter Notebook format to provide a clear step-by-step guide through the entire process, from data preprocessing to model training and evaluation.

## Requirements

Below are the package versions used in this project. Make sure to install these specific versions for compatibility with the code provided.

```bash
numpy==1.22.0
torch==1.12.0+cu102
torchtext==0.13.0
torchvision==0.13.0+cu102
tqdm==4.64.0
```
## To install the requirements, run the following command:
pip install -r requirements.txt
